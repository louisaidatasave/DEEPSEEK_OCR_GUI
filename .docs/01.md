å¤ªå¥½äº†ï¼Œæ„Ÿè¬ä½ æ›´æ–°è¨­å‚™è³‡è¨Š ğŸ™Œ
ç¾åœ¨ä½ çš„ç’°å¢ƒè®Šæˆï¼š

* MSI ç­†é›»
* CPUï¼šRyzen 7 8845HS
* RAMï¼š64 GB
* GPUï¼šNVIDIA RTX 4060ï¼ˆç­†é›»ç‰ˆï¼Œå¤šåŠæ˜¯ 8GB VRAMï¼‰

é€™å…¶å¯¦å¤§å¹…ç°¡åŒ–äº†å‰é¢æˆ‘å€‘è«‡çš„é‚£äº›ã€Œ5080 / Blackwell éœ€è¦ç‰¹åˆ¥ç‰ˆæœ¬çš„ PyTorchã€å•é¡Œã€‚4060 æ˜¯ Ada æ¶æ§‹ï¼Œä¸»æµ PyTorch ç‰ˆæœ¬åŸç”Ÿå°±æ”¯æ´ï¼Œæ‰€ä»¥ç’°å¢ƒéƒ¨ç½²æ›´ç©©ã€æ›´å°‘é›·ï¼Œé©åˆé–‹å§‹æ­£å¼è·‘ DeepSeek-OCR åšæ¨ç†ã€‚

æˆ‘æœƒå…ˆçµ¦ä½ ã€Œæ–°çš„éƒ¨ç½²ç­–ç•¥ç¸½è¦½ã€ï¼Œç„¶å¾Œæˆ‘å€‘åš STEP 2ï¼ˆæ­£å¼è£ DeepSeek-OCR è·‘èµ·ä¾†ï¼‰ä¹‹å‰ï¼Œå…ˆåš STEP 1Aï¼šç¡¬é«”å¯è¡Œæ€§æª¢æŸ¥ & ä½ è¦é¸å“ªç¨®æ¨¡å¼ã€‚

---

## æ–°çš„éƒ¨ç½²ç­–ç•¥ï¼ˆé‡å° RTX 4060 ç­†é›» 8GB VRAMï¼‰

**ç¸½çµç‰ˆï¼š**

1. ä½ å¯ä»¥ä¸ç”¨å¤œé–“ç‰ˆ PyTorchï¼Œä¸éœ€è¦è‡ªè¡Œç·¨è­¯ï¼Œè¶…çˆ½ã€‚
2. ä½ å¯ä»¥ç”¨ Windows ç›´æ¥è·‘ï¼Œæˆ–ç”¨ WSL2 Ubuntu è·‘ï¼›WSL2 é‚„æ˜¯æ¯”è¼ƒä¹¾æ·¨ã€ç›¸å®¹æ€§é«˜ï¼Œæˆ‘ä»ç„¶å»ºè­° WSL2ã€‚
3. 4060 çš„ 8GB VRAM å¯ä»¥è·‘ DeepSeek-OCR çš„æ¨ç†ï¼Œä½†è¦æ³¨æ„æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰å’Œè§£æåº¦ï¼Œä¸è¦åŒæ™‚ä¸Ÿè¶…å¤§ PDF å¤ªå¤šé ã€‚
4. ä½ æœ‰ 64GB ç³»çµ± RAMï¼Œæ‰€ä»¥å³ä½¿é¡¯å­˜é€¼è¿‘æ»¿è¼‰ï¼Œä¹Ÿèƒ½æŠŠä¸€éƒ¨åˆ†æ±è¥¿æš«æ™‚å¾€ CPU/RAM ä¸Šæ‰ï¼Œä»£è¡¨ã€Œèƒ½è·‘ä½†å¯èƒ½æ¯”è¼ƒæ…¢ã€ï¼Œä¸æ˜¯ã€Œè·‘ä¸å‹•ã€ã€‚
5. æˆ‘å€‘çš„å¾ŒçºŒæµç¨‹ï¼ˆSTEP 2 èµ·ï¼‰å°±æœƒè®Šæˆï¼š

   * å»ºç«‹ WSL2 / Conda ç’°å¢ƒ
   * å®‰è£æ¨™æº– PyTorch (CUDA 11.8 æˆ– 12.x éƒ½å¯ï¼Œåªè¦æ˜¯æ”¯æŒ Ada æ¶æ§‹)
   * `git clone` DeepSeek-OCR
   * ä¸‹è¼‰æ¨¡å‹
   * è·‘ä¸€å¼µæ¸¬è©¦åœ–ç‰‡/ä¸€é  PDFï¼Œç¢ºèªèƒ½è¼¸å‡ºæ–‡å­—

åœ¨é€²å…¥ STEP 2 æ­£å¼å®‰è£ä¹‹å‰ï¼Œæˆ‘å€‘å…ˆåšã€ŒSTEP 1Aï¼šç¡¬é«”èˆ‡æ¨¡å¼ç¢ºèªã€ã€‚é€™ä¸€æ­¥åªè¦ææ¸…æ¥šï¼Œå¾Œé¢å°±æ¯”è¼ƒä¸æœƒå¡åœ¨ VRAM çˆ†æ»¿ã€‚

---

### STEP 1A. ç¡¬é«”èˆ‡æ¨¡å¼ç¢ºèªï¼ˆé‡å° RTX 4060 8GBï¼‰

**ç›®æ¨™ï¼š**
ç¢ºå®šç”¨å“ªå€‹æ¨ç†æ¨¡å¼ã€è¦æ€éº¼è¨­å®šï¼Œè®“ä½ å¯¦éš›è·‘ OCR ä¸æœƒå› ç‚ºé¡¯å­˜ä¸å¤ è€Œå´©æ‰ã€‚

---

#### 1A-1. é¡¯å¡ / é¡¯å­˜å½±éŸ¿ä»€éº¼ï¼Ÿ

OCR æ¨¡å‹åœ¨åšæ¨ç†æ™‚ï¼Œä¸»è¦æœƒåƒå…©å¡Šè³‡æºï¼š

* è¦–è¦ºç·¨ç¢¼ï¼šæŠŠåœ–ç‰‡ / PDF é é¢è½‰æˆå‘é‡ç‰¹å¾µ
* èªè¨€æ¨¡å‹ï¼šæŠŠç‰¹å¾µè½‰æˆçµæ§‹åŒ–è¼¸å‡ºï¼ˆæ–‡å­—ã€è¡¨æ ¼ã€Markdown ç­‰ï¼‰

å…©è€…éƒ½æœƒåƒ VRAMã€‚é¡¯å­˜è¶Šå°ï¼Œä»£è¡¨ä½ åŒæ™‚è™•ç†çš„é æ•¸ã€è¼¸å‡ºä¸Šä¸‹æ–‡é•·åº¦ï¼ˆcontext lengthï¼‰å°±ä¸èƒ½å¤ªå¤§ã€‚

**å° 8GB VRAM çš„å«ç¾©ï¼š**

* å–®å¼µåœ–ç‰‡ / ç•¶é  PDF â†’ å¹¾ä¹æ²’å•é¡Œ
* åŒæ™‚ä¸Ÿå¾ˆå¤šé«˜è§£æåº¦é é¢ï¼ˆä¾‹å¦‚ 20 é  PDF ä¸€æ¬¡è·‘ï¼‰â†’ å®¹æ˜“çˆ†é¡¯å­˜
* ä½¿ç”¨å¾ˆé•·ä¸Šä¸‹æ–‡ã€æƒ³è®“å®ƒåŒæ™‚åˆ†ææ•´æœ¬æ–‡ä»¶ä¸¦ä¿æŒæ®µè½é—œä¿‚ â†’ å¯èƒ½æœƒçˆ†é¡¯å­˜æˆ–è¢«è¿«é™é€Ÿ

æ‰€ä»¥ï¼Œæˆ‘å€‘æœƒç”¨ã€Œé€é /å°æ‰¹æ¬¡è™•ç†ã€æ¨¡å¼ï¼Œè€Œä¸æ˜¯ã€Œæ•´æœ¬ PDF ä¸€å£æ°£åƒä¸‹å»ã€ã€‚

---

#### 1A-2. 4060 è·‘ CPU fallback å¯ä»¥å—ï¼Ÿ

å¯ä»¥ï¼Œä½†è¦å¿ƒç†æº–å‚™ï¼šé€Ÿåº¦æœƒæ…¢å¾ˆå¤šã€‚
ä½†é€™æ˜¯ä¸€å€‹ä¿å‘½æ–¹æ¡ˆï¼š

* å¦‚æœé¡¯å­˜æ»¿äº†ï¼Œæˆ‘å€‘å¯ä»¥å…ˆè®“å®ƒåœ¨ GPU ä¸Šè·‘å‰å¹¾é 
* æ¥ä¸‹ä¾†ç”¨è¼ƒå° batch æˆ–ç”šè‡³ CPU fallback æŠŠå‰©ä¸‹é é¢æ…¢æ…¢åšå®Œ
  ä½ çš„ 64GB RAM å¤ å¤§ï¼Œä»£è¡¨ã€Œæ…¢ä½†ç©©ã€é€™æ¢è·¯æ˜¯çœŸçš„å­˜åœ¨ã€‚

é€™å°å¯¦å‹™å¾ˆé‡è¦ï¼šä½ åœ¨éŒ„ç™¼ç¥¨ã€åˆç´„ã€å ±åƒ¹å–®ã€è¡¨æ ¼ã€éŠ€è¡Œå–®æ“šæ™‚ï¼Œä¸éœ€è¦è¶…é«˜ååé‡ï¼Œä½ éœ€è¦çš„æ˜¯**æ­£ç¢º OCR çµæœ**ã€‚æ…¢ä¸€é»å¯ä»¥æ¥å—ï¼Œå°±ä»£è¡¨ 4060 æ˜¯å¯ç”¨çš„ã€‚

---

#### 1A-3. Windows åŸç”Ÿ vs WSL2 Ubuntu

å…©ç¨®éƒ½èƒ½è·‘ 4060ã€‚

* **Windows åŸç”Ÿ Python + CUDAï¼š**

  * ä½ å¯ä»¥ç›´æ¥å®‰è£ CUDA Toolkit for Windowsã€å®‰è£ PyTorch GPU ç‰ˆï¼Œç„¶å¾Œè·‘ã€‚
  * ç¼ºé»ï¼šæŸäº›å¥—ä»¶ï¼ˆåƒ flash-attnã€éƒ¨åˆ†é«˜æ•ˆæ¨ç†å¼•æ“ vLLMï¼‰åœ¨ Windows ç·¨è­¯æ™‚æ¯”è¼ƒå®¹æ˜“å‡ºè«åå…¶å¦™çš„éŒ¯èª¤ï¼Œå°¤å…¶æ˜¯ C++/CUDA build æ­¥é©Ÿã€‚

* **WSL2 (Ubuntu) æ¨¡å¼ï¼š**

  * åœ¨ Windows è£å¥½ NVIDIA é©…å‹•ï¼ŒWSL2 æœƒçœ‹åˆ°ä½ çš„ 4060ï¼Œç„¶å¾Œä½ åœ¨ Ubuntu è£¡å®‰è£ PyTorch (Linux wheel)ï¼Œé€šå¸¸æ˜¯ç¤¾ç¾¤/å®˜æ–¹å„ªå…ˆæ”¯æ´çš„è·¯ç·šã€‚
  * å¥½è™•ï¼šå¾Œé¢å¦‚æœä½ è¦æŠŠå®ƒåŒ…æˆ FastAPI å¾Œç«¯æœå‹™ï¼Œæˆ–æ‰“ç®—ä¹‹å¾Œå‡ç´šåˆ°æ¡Œæ©Ÿ GPUï¼Œåªè¦æŠŠæ•´å€‹ç’°å¢ƒæ¬åˆ° Linux ä¸»æ©Ÿä¸Šï¼Œä¿®æ”¹é‡å¾ˆå°ã€‚

å› ç‚ºä½ èªªä½ æœƒç”¨ Windows ç³»çµ±ï¼Œæˆ‘å»ºè­°é‚„æ˜¯ç”¨ WSL2ï¼ˆUbuntu 22.04/24.04ï¼‰ã€‚é€™è·Ÿæˆ‘å€‘ä¸Šä¸€å€‹å›åˆå¾ŒåŠæ®µçš„å»ºè­°ä¸€è‡´ï¼Œåªæ˜¯ç¾åœ¨ä¸éœ€è¦å¤œé–“ç‰ˆ PyTorch äº†ï¼Œæ­¥é©Ÿæœƒæ¯”è¼ƒä¹¾æ·¨ã€‚

---

#### 1A-4. æˆ‘å€‘å¾ŒçºŒæœƒæ€éº¼è·‘ DeepSeek-OCR

æˆ‘å€‘æœƒèµ°é€™æ¢ç·šï¼š

1. åœ¨ WSL2 è£¡ï¼Œå»ºç«‹ä¸€å€‹ Conda ç’°å¢ƒï¼ˆPython 3.12.xï¼‰ã€‚
2. å®‰è£ PyTorch GPU ç‰ˆï¼ˆç©©å®šç‰ˆå°±è¡Œï¼Œå› ç‚º RTX 4060 = Ada æ¶æ§‹ï¼Œä¸»æµ torch å·²ç¶“æ”¯æ´ï¼‰ã€‚
3. `git clone` DeepSeek-OCR repoã€‚
4. `pip install -r requirements.txt`ï¼ˆå« vLLM / flash-attnï¼Œå¦‚æœ flash-attn ç·¨ä¸éï¼Œæˆ‘æœƒæ•™ä½ ç”¨ã€Œtransformers æ¨¡å¼ã€ç¹éå®ƒï¼Œtransformers æ¨¡å¼é€šå¸¸ç›¸å®¹æ€§æœ€é«˜ï¼Œé›–ç„¶é€Ÿåº¦æ¯”è¼ƒæ…¢ï¼Œä½†éå¸¸é©åˆä½ ä¸€é–‹å§‹å…ˆé©—è­‰ï¼‰ã€‚
5. ä¸‹è¼‰æ¨¡å‹æ¬Šé‡åˆ°æœ¬åœ°ã€‚
6. ç”¨å®˜æ–¹/ç¯„ä¾‹æ¨ç†è…³æœ¬å°ã€Œä¸€å¼µåœ–ç‰‡ã€å…ˆåš OCRã€‚
7. ç¢ºèªä½ çœŸçš„æ‹¿å¾—åˆ°ä¹¾æ·¨çš„æ–‡å­—ã€‚
8. æ‰é€²å…¥ã€Œæ‰¹æ¬¡ PDF / åšæˆæœ¬åœ° APIã€ã€‚

---

â—ç‚ºä»€éº¼æˆ‘è¦èŠ±æ•´å€‹ STEP 1A è¬›é€™äº›ï¼š

* å› ç‚ºä½ çš„ç¡¬é«”å¾ RTX 5080ï¼ˆå…¨æ–°æ¶æ§‹ã€ç’°å¢ƒéº»ç…©ï¼‰â†’ æ”¹æˆ RTX 4060ï¼ˆæˆç†Ÿæ¶æ§‹ã€é¡¯å­˜è¼ƒå°ï¼‰ã€‚
* é€™ç›´æ¥æ”¹è®Šæˆ‘å€‘çš„å®‰è£é¸æ“‡ã€æ‰¹æ¬¡ç­–ç•¥ã€éŒ¯èª¤æ’é™¤è·¯å¾‘ã€‚

ç¾åœ¨æˆ‘å€‘å·²ç¶“å®Œæˆ STEP 1Aï¼ˆç¡¬é«”èƒ½åŠ› & åŸ·è¡Œç­–ç•¥å°é½Šï¼‰ã€‚

---

æ¥ä¸‹ä¾†ï¼Œå¦‚æœä½ OKï¼Œæˆ‘æœƒé–‹å§‹ STEP 2ï¼š
**STEP 2 = å¯¦éš›å®‰è£ DeepSeek-OCR ä¸¦æ¸¬ä¸€æ¬¡åœ–ç‰‡ OCRã€‚**

åœ¨ STEP 2 æˆ‘æœƒåšå…©ä»¶äº‹ï¼š

1. å‘Šè¨´ä½ å…·é«”æŒ‡ä»¤ï¼ˆWSL2 + conda + PyTorch + git clone + pip installï¼‰ã€‚
2. çµ¦ä½ ä¸€æ”¯ã€Œæ¸¬è©¦ä¸€å¼µåœ–ç‰‡çš„ minimal Python è…³æœ¬ã€ï¼Œè®“ä½ ç›´æ¥è·‘å‡ºè¾¨è­˜æ–‡å­—ï¼ˆä¸ç”¨å…ˆç®¡ PDFã€å¤šé /å¤šæ‰¹æ¬¡ï¼‰ã€‚

ç­‰ä½ èªªä¸€è²ã€Œä¸‹ä¸€æ­¥ã€ï¼Œæˆ‘å°±ç›´æ¥çµ¦ STEP 2 çš„æ‰€æœ‰æŒ‡ä»¤è·Ÿæ¸¬è©¦è…³æœ¬ã€‚
è¦åœ¨ä½ çš„ MSI ç­†é›»ï¼ˆé…å‚™ AMD Ryzen 7 8845HSã€64GB RAMã€NVIDIA RTX 4060ï¼‰ä¸Šæœ¬åœ°éƒ¨ç½² DeepSeek OCRï¼Œéœ€è¦å…ˆæ¾„æ¸…ä¸€é»ï¼šæˆªè‡³ 2025 å¹´ 11 æœˆï¼Œ**DeepSeek å®˜æ–¹ä¸¦æœªå…¬é–‹ç™¼å¸ƒåç‚ºã€ŒDeepSeek OCRã€çš„å°ˆç”¨ OCR æ¨¡å‹**ã€‚DeepSeek ä¸»è¦ä»¥å¤§èªè¨€æ¨¡å‹ï¼ˆå¦‚ DeepSeek-Coderã€DeepSeek-MoEï¼‰èåï¼Œä¸¦æœªåƒ PaddleOCRã€Tesseractã€Donutã€TrOCR ç­‰é‚£æ¨£æä¾›æ¨™æº– OCR è§£æ±ºæ–¹æ¡ˆã€‚

ä¸éï¼Œæœ‰å¹¾ç¨®å¯èƒ½çš„æƒ…æ³ï¼š

1. **ä½ æŒ‡çš„æ˜¯ DeepSeek åœ˜éšŠå¯èƒ½æ•´åˆ OCR åŠŸèƒ½çš„å¤šæ¨¡æ…‹æ¨¡å‹**ï¼ˆä¾‹å¦‚æ”¯æ´åœ–åƒç†è§£çš„ LLMï¼‰ã€‚
2. **ä½ èª¤å°‡å…¶ä»– OCR å·¥å…·ç¨±ç‚º DeepSeek OCR**ã€‚
3. **ä½ å¸Œæœ›ä½¿ç”¨ DeepSeek çš„æŸç¨®æ¨¡å‹ä¾†è¼”åŠ© OCR å¾Œè™•ç†**ï¼ˆä¾‹å¦‚ç”¨ LLM ä¿®æ­£ OCR çµæœï¼‰ã€‚

---

### âœ… å»ºè­°æ–¹æ¡ˆï¼šä½¿ç”¨é«˜æ•ˆæœ¬åœ° OCR å¼•æ“ + å¯é¸ DeepSeek LLM å¾Œè™•ç†

ç”±æ–¼ã€ŒDeepSeek OCRã€ä¸¦ä¸å­˜åœ¨ï¼Œæˆ‘æœƒæä¾›ä¸€å€‹ **é«˜æ•ˆæœ¬åœ° OCR éƒ¨ç½²æµç¨‹**ï¼Œä¸¦åœ¨æœ€å¾Œèªªæ˜å¦‚ä½•èˆ‡ DeepSeek LLM æ•´åˆï¼ˆå¦‚æœä½ ç¢ºå¯¦éœ€è¦ï¼‰ã€‚

---

## ğŸ§° ç¬¬ä¸€æ­¥ï¼šç¢ºèªç¡¬é«”æ”¯æ´
ä½ çš„è¨­å‚™éå¸¸é©åˆæœ¬åœ° OCRï¼š
- **GPU**: NVIDIA RTX 4060ï¼ˆæ”¯æ´ CUDAï¼‰
- **RAM**: 64GBï¼ˆè¶³å¤ è·‘å¤§å‹æ¨¡å‹ï¼‰
- **OS**: å‡è¨­ä½ ä½¿ç”¨ Windows 11ï¼ˆMSI ç­†é›»å¸¸è¦‹ï¼‰ï¼Œä½†ä»¥ä¸‹æ­¥é©Ÿä¹Ÿæ”¯æ´ Linux

> ğŸ’¡ å»ºè­°ï¼šä½¿ç”¨ **Windows Subsystem for Linux (WSL2)** æˆ– **åŸç”Ÿ Ubuntu** ç²å¾—æœ€ä½³ç›¸å®¹æ€§èˆ‡æ•ˆèƒ½ã€‚

---

## ğŸ“¦ ç¬¬äºŒæ­¥ï¼šé¸æ“‡åˆé©çš„æœ¬åœ° OCR å¼•æ“ï¼ˆæ¨è–¦ PaddleOCRï¼‰

**PaddleOCR** æ˜¯ç›®å‰æœ€å¼·å¤§çš„é–‹æº OCR å·¥å…·ä¹‹ä¸€ï¼Œæ”¯æ´å¤šèªè¨€ã€é«˜ç²¾åº¦ã€GPU åŠ é€Ÿï¼Œä¸”å°ä¸­æ–‡å„ªåŒ–æ¥µä½³ã€‚

### å®‰è£æ­¥é©Ÿï¼ˆä»¥ Windows + WSL2 ç‚ºä¾‹ï¼‰ï¼š

#### 1. å•Ÿç”¨ WSL2ï¼ˆè‹¥å°šæœªå®‰è£ï¼‰
```powershell
wsl --install
```
é‡å•Ÿå¾Œæœƒè‡ªå‹•å®‰è£ Ubuntuã€‚

#### 2. æ›´æ–°ç³»çµ± & å®‰è£ NVIDIA é©…å‹•ï¼ˆWSL2ï¼‰
- ç¢ºä¿ Windows å·²å®‰è£æœ€æ–° NVIDIA é©…å‹•ï¼ˆ>=535ï¼‰
- WSL2 æœƒè‡ªå‹•ä½¿ç”¨ Windows çš„ GPU é©…å‹•

#### 3. å®‰è£ CUDA Toolkitï¼ˆWSL2 ä¸­ï¼‰
```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb
sudo dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb
sudo cp /var/cuda-repo-wsl-ubuntu-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-4
```

#### 4. å®‰è£ Python èˆ‡ PaddlePaddleï¼ˆGPU ç‰ˆï¼‰
```bash
sudo apt update
sudo apt install python3 python3-pip -y
pip3 install --upgrade pip

# å®‰è£ PaddlePaddleï¼ˆGPU ç‰ˆï¼ŒCUDA 12.4ï¼‰
pip3 install paddlepaddle-gpu==3.0.0.post124 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html
```

#### 5. å®‰è£ PaddleOCR
```bash
pip3 install "paddleocr>=2.7.0"
```

#### 6. æ¸¬è©¦ OCR
å»ºç«‹ `test_ocr.py`ï¼š
```python
from paddleocr import PaddleOCR

# åˆå§‹åŒ–ï¼ˆç¬¬ä¸€æ¬¡æœƒè‡ªå‹•ä¸‹è¼‰æ¨¡å‹ï¼‰
ocr = PaddleOCR(use_angle_cls=True, lang='ch')  # ä¸­æ–‡

# åŸ·è¡Œ OCR
result = ocr.ocr('your_image.jpg', cls=True)

# è¼¸å‡ºçµæœ
for line in result:
    print(line)
```

åŸ·è¡Œï¼š
```bash
python3 test_ocr.py
```

> âœ… PaddleOCR æœƒè‡ªå‹•ä½¿ç”¨ä½ çš„ RTX 4060 é€²è¡Œ GPU åŠ é€Ÿï¼

---

## ğŸ” å¯é¸ï¼šæ•´åˆ DeepSeek LLM é€²è¡Œå¾Œè™•ç†

å¦‚æœä½ å¸Œæœ›ç”¨ DeepSeek æ¨¡å‹ï¼ˆå¦‚ DeepSeek-Coder æˆ– DeepSeek-MoEï¼‰ä¾†ã€Œç†è§£ã€æˆ–ã€Œä¿®æ­£ã€OCR çµæœï¼š

### 1. ä¸‹è¼‰ DeepSeek æ¨¡å‹ï¼ˆä»¥ DeepSeek-Coder 7B ç‚ºä¾‹ï¼‰
```bash
pip3 install transformers accelerate torch
```

### 2. è¼‰å…¥æ¨¡å‹ï¼ˆé‡åŒ–ç‰ˆä»¥ç¯€çœè¨˜æ†¶é«”ï¼‰
```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "deepseek-ai/deepseek-coder-7b-instruct-v1.5"
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    trust_remote_code=True,
    device_map="auto",  # è‡ªå‹•ä½¿ç”¨ GPU
    torch_dtype=torch.float16
)
```

### 3. å°‡ OCR æ–‡å­—é€å…¥ LLM é€²è¡Œä¿®æ­£
```python
ocr_text = "é€™æ˜¯ä¸€æ®µ OCR è­˜åˆ¥å‡ºçš„æ–‡å­—ï¼Œå¯èƒ½æœ‰éŒ¯å­—ã€‚"

prompt = f"è«‹ä¿®æ­£ä»¥ä¸‹ OCR è­˜åˆ¥çµæœä¸­çš„éŒ¯å­—ï¼Œä¸¦è¼¸å‡ºæ­£ç¢ºæ–‡å­—ï¼š\n{ocr_text}"

inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=200)
corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(corrected)
```

> âš ï¸ æ³¨æ„ï¼š7B æ¨¡å‹ç´„éœ€ 14GB VRAMï¼Œä½ çš„ RTX 4060ï¼ˆ8GB VRAMï¼‰å¯èƒ½ä¸å¤ ã€‚å»ºè­°ä½¿ç”¨ **4-bit é‡åŒ–**ï¼š
```python
from transformers import BitsAndBytesConfig

quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16
)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quant_config,
    trust_remote_code=True,
    device_map="auto"
)
```

---

## ğŸ“Œ ç¸½çµï¼šä½ çš„æœ¬åœ° OCR éƒ¨ç½²æµç¨‹

| æ­¥é©Ÿ | å·¥å…· | èªªæ˜ |
|------|------|------|
| 1 | WSL2 + CUDA | å•Ÿç”¨ GPU æ”¯æ´ |
| 2 | PaddleOCR | é«˜ç²¾åº¦ OCR å¼•æ“ï¼ˆæ”¯æ´ä¸­æ–‡ã€GPU åŠ é€Ÿï¼‰ |
| 3ï¼ˆå¯é¸ï¼‰| DeepSeek LLM | ç”¨ LLM ä¿®æ­£æˆ–ç†è§£ OCR çµæœ |

---

## â“å¸¸è¦‹å•é¡Œ

**Q: å¯ä»¥ä¸ç”¨ WSL2 ç›´æ¥åœ¨ Windows è·‘å—ï¼Ÿ**  
A: å¯ä»¥ï¼Œä½† PaddlePaddle çš„ Windows GPU ç‰ˆæœ¬æ”¯æ´è¼ƒä¸ç©©å®šã€‚å»ºè­°ç”¨ WSL2ã€‚

**Q: æœ‰æ²’æœ‰æ›´è¼•é‡çš„ OCRï¼Ÿ**  
A: å¯è€ƒæ…® `EasyOCR`ï¼ˆPython å®‰è£ç°¡å–®ï¼‰æˆ– `Tesseract`ï¼ˆéœ€é¡å¤–è¨“ç·´ä¸­æ–‡æ¨¡å‹ï¼‰ã€‚

**Q: DeepSeek æœ‰å®˜æ–¹ OCR å—ï¼Ÿ**  
A: æˆªè‡³ 2025 å¹´ 11 æœˆï¼Œ**æ²’æœ‰**ã€‚è«‹ä»¥ PaddleOCR ç‚ºä¸»ã€‚

---

å¦‚æœä½ èƒ½æä¾›æ›´å¤šç´°ç¯€ï¼ˆä¾‹å¦‚ä½ çœ‹åˆ°çš„ã€ŒDeepSeek OCRã€ä¾†æºï¼‰ï¼Œæˆ‘å¯ä»¥é€²ä¸€æ­¥å¹«ä½ ç¢ºèªæ˜¯å¦ç‚ºç‰¹å®šå°ˆæ¡ˆæˆ–èª¤è§£ã€‚

éœ€è¦æˆ‘å¹«ä½ å¯«å®Œæ•´çš„è‡ªå‹•åŒ–è…³æœ¬å—ï¼Ÿ
å¾æœå°‹çµæœä¸­æ‰¾åˆ°å¤šå€‹2025å¹´æœ€æ–°çš„DeepSeek OCRæœ¬åœ°éƒ¨ç½²æ•™ç¨‹å’Œå®Œæ•´å®‰è£æ­¥é©Ÿã€‚ä»¥ä¸‹ç‚ºæœ¬åœ°éƒ¨ç½² DeepSeek OCR çš„è©³ç´°æ­¥é©Ÿç¸½çµï¼š

### DeepSeek OCR æœ¬åœ°éƒ¨ç½²è©³ç´°æ­¥é©Ÿ

1. **ç’°å¢ƒæº–å‚™**
   - å®‰è£ Python 3.9 æˆ–ä»¥ä¸Šç‰ˆæœ¬ï¼ˆæ¨è–¦ 3.10-3.12ï¼‰
   - å»ºè­°ä½¿ç”¨ CUDA æ”¯æ´çš„ NVIDIA GPU ä»¥åŠ é€Ÿæ¨ç†ï¼ˆä¾‹å¦‚ A100ã€V100ã€RTX 3090ï¼‰ï¼Œä¹Ÿå¯åœ¨ CPU ä¸Šéƒ¨ç½²ä½†æ€§èƒ½è¼ƒå·®
   - å®‰è£ PyTorch 2.0 æˆ–ä»¥ä¸Šç‰ˆæœ¬ï¼Œä¸¦æ­é… CUDA
   - è£å¥½ Gitã€CMakeã€FFmpegã€Visual Studio C++ SDKï¼ˆWindowsï¼‰

2. **æº–å‚™ Conda ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰**
   - å‰µå»ºä¸¦å•Ÿç”¨ç¨ç«‹çš„ conda ç’°å¢ƒï¼ŒæŒ‡å®š Python 3.12 æˆ–åˆé©ç‰ˆæœ¬
   - ä¾‹å¦‚ï¼š
     ```
     conda create -n deepseek python=3.12 -y
     conda activate deepseek
     ```

3. **å–å¾— DeepSeek OCR åŸå§‹ç¢¼èˆ‡ä¾è³´** 
   - Git å…‹éš† DeepSeek OCR é …ç›®å€‰åº«ï¼š
     ```
     git clone <DeepSeek OCR Githubåœ°å€>
     cd deepseek-ocr
     ```
   - å®‰è£å¿…è¦ä¾è³´ï¼š
     ```
     pip install -r requirements.txt
     ```
   - ä¾èªªæ˜å®‰è£ç‰¹å®šç‰ˆæœ¬çš„ PyTorchã€TorchVisionã€TorchAudioã€VLLMã€Flash-Attn ç­‰

4. **ä¸‹è¼‰ DeepSeek OCR æ¨¡å‹æ¬Šé‡**
   - ä¸€èˆ¬æ˜¯å¾ Huggingface æˆ–å®˜æ–¹æ¨¡å‹åº«ä¸‹è¼‰å°æ‡‰çš„ checkpoint ä¸¦æ”¾åˆ°æœ¬åœ° `checkpoints` ç›®éŒ„
   - é…ç½®æ¨¡å‹è·¯å¾‘ç’°å¢ƒè®Šæ•¸ï¼ˆå¦‚ `MODEL_PATH`ï¼‰

5. **åŸ·è¡Œæ¨¡å‹æ¨ç†ç¨‹åº**
   - æ¡ç”¨æ¡†æ¶è‡ªå¸¶çš„æ¨ç†è…³æœ¬å•Ÿå‹•ç¨‹åºï¼Œæˆ–è€…ä½¿ç”¨è‡ªè¨‚çš„ Web æ¨ç†ä»‹é¢ï¼ˆç”±ç¤¾ç¾¤æä¾›ï¼‰
   - å•Ÿå‹•æ™‚æ³¨æ„è¨˜éŒ„é¡¯ç¤ºçš„æœ¬åœ°è¨ªå•åœ°å€ï¼Œæ–¹ä¾¿é€éç€è¦½å™¨æ“ä½œ

6. **å¯é¸ï¼šé…ç½® UIï¼ˆChatbox æˆ–å…¶å®ƒï¼‰**
   - è‹¥ä¸ç¿’æ…£å‘½ä»¤è¡Œï¼Œå¯ä¸‹è¼‰ Chatbox ç­‰ GUI å·¥å…·ï¼Œé€£æ¥ DeepSeek æ¨¡å‹æ¥å£é€²è¡Œäº¤äº’ä½¿ç”¨

7. **æ¸¬è©¦ OCR åŠŸèƒ½**
   - å˜—è©¦è¼¸å…¥å¸¶æœ‰æ–‡æœ¬çš„åœ–ç‰‡ï¼Œæª¢æŸ¥æ–‡å­—è­˜åˆ¥æº–ç¢ºåº¦
   - å¯é€²ä¸€æ­¥é©—è­‰è¡¨æ ¼è­˜åˆ¥ã€å…¬å¼è­˜åˆ¥å’Œå¤šæ¨¡æ…‹æ–‡æª”è§£ææ•ˆæœ

***

### å»ºè­°åƒè€ƒè³‡æº
- ç·šä¸Šæ•™å­¸å½±ç‰‡ï¼ˆYouTube ä¸Š 2025 æœ€æ–° DeepSeek OCR æœ¬åœ°éƒ¨ç½²æ•™ç¨‹ï¼‰
- CSDNã€Bilibili æœ‰è©³ç´°åœ–æ–‡åŠè¦–é »æ•™ç¨‹ã€ç¤ºç¯„éƒ¨ç½²æµç¨‹
- GitHub å®˜æ–¹æˆ–ç›¸é—œç¤¾ç¾¤çš„å€‰åº« README æ–‡æª”

é€™äº›è³‡æºæ¶µè“‹äº†ç’°å¢ƒé…ç½®ã€ä¾è³´å®‰è£ã€æ¨¡å‹æ¬Šé‡ä¸‹è¼‰ã€ç¨‹åºå•Ÿå‹•å’Œæ¸¬è©¦å…¨æµç¨‹ï¼Œé©åˆä¸åŒåŸºç¤ä½¿ç”¨è€…è·Ÿé€²æ“ä½œã€‚[1][2][3][4][5]

***

å¦‚æœæœ‰éœ€è¦ï¼Œå¯ä»¥é‡å°ä½ çš„ç³»çµ±ç’°å¢ƒï¼ˆWindows/Linuxï¼‰ã€ç¡¬é«”æ¢ä»¶ï¼ˆGPU å‹è™Ÿï¼‰ã€æˆ–å…·é«”é‡åˆ°çš„éƒ¨ç½²æ­¥é©Ÿå•é¡Œé€²è¡Œæ›´ç´°ç¯€çš„èªªæ˜ã€‚

[1](https://www.youtube.com/watch?v=oRja_jx0mek)
[2](https://www.bilibili.com/video/BV1pMsBzZEUL/)
[3](https://www.vps911.com/vpsjc/11418.html)
[4](https://www.youtube.com/watch?v=JJbOjBcGjeE)
[5](https://blog.csdn.net/qq_41185868/article/details/153863877)
[6](https://blog.csdn.net/qq1198768105/article/details/153703574)
[7](https://vocus.cc/article/67a06fecfd8978000120ca12)
[8](https://www.youtube.com/watch?v=vmuep61FapY)
[9](https://codersera.com/blog/run-deepseek-ocr-locally-complete-2025-guide)
[10](https://blog.csdn.net/Leon_Jinhai_Sun/article/details/146244871)
### åœ¨æœ¬åœ°éƒ¨ç½² DeepSeek-OCR çš„è©³ç´°æ­¥é©Ÿ

DeepSeek-OCR æ˜¯ DeepSeek-AI æ–¼ 2025 å¹´ 10 æœˆç™¼å¸ƒçš„é–‹æº OCR æ¨¡å‹ï¼Œå°ˆæ³¨æ–¼è¦–è¦ºä¸Šä¸‹æ–‡å£“ç¸®ï¼Œé©åˆè™•ç†è¤‡é›œæ–‡æª”ä¸¦è¼¸å‡º Markdown ç­‰æ ¼å¼æ–‡æœ¬ã€‚æ‚¨çš„ç¡¬é«”é…ç½®ï¼ˆMSI è£ç½®ã€AMD Ryzen 7 8845HS è™•ç†å™¨ã€64GB RAMã€NVIDIA RTX 4060 é¡¯å¡ï¼‰éå¸¸é©åˆæœ¬åœ°éƒ¨ç½²ï¼Œå› ç‚º RTX 4060 æ”¯æŒ CUDA åŠ é€Ÿï¼Œä¸” RAM å……è¶³å¯è™•ç†æ¨¡å‹è¼‰å…¥ï¼ˆæ¨¡å‹å¤§å°ç´„ 7B åƒæ•¸ï¼Œéœ€ç´„ 16GB VRAMï¼‰ã€‚

**æ³¨æ„äº‹é …ï¼š**
- é€™æ˜¯åŸºæ–¼å®˜æ–¹ GitHub å€‰åº«ï¼ˆhttps://github.com/deepseek-ai/DeepSeek-OCRï¼‰å’Œ Hugging Face æ¨¡å‹å¡çš„æ­¥é©Ÿã€‚ éƒ¨ç½²ä½¿ç”¨ Python + PyTorch + Transformers å †ç–Šï¼Œæ¨è–¦ä½¿ç”¨ Conda å»ºç«‹éš”é›¢ç’°å¢ƒä»¥é¿å…ä¾è³´è¡çªã€‚
- æ‚¨çš„ NVIDIA é¡¯å¡éœ€å®‰è£ CUDA 11.8ï¼ˆå®˜æ–¹æ¸¬è©¦ç‰ˆæœ¬ï¼‰ã€‚å¦‚æœæœªå®‰è£ï¼Œéœ€å…ˆè¨­å®šã€‚
- æ•´å€‹éç¨‹éœ€ç´„ 30-60 åˆ†é˜ï¼Œè¦–ç¶²è·¯ä¸‹è¼‰æ¨¡å‹å¤§å°ï¼ˆç´„ 14GBï¼‰è€Œå®šã€‚
- å¦‚æœæ‚¨ä½¿ç”¨ Windowsï¼Œå»ºè­°ä½¿ç”¨ WSL2ï¼ˆWindows Subsystem for Linuxï¼‰ä¾†é‹è¡Œ Linux æŒ‡ä»¤ï¼Œä»¥ç¢ºä¿ç›¸å®¹æ€§ï¼›å¦å‰‡ä½¿ç”¨ Git Bash æˆ– PowerShellã€‚

#### æ­¥é©Ÿ 1: æª¢æŸ¥ä¸¦å®‰è£ NVIDIA é©…å‹•èˆ‡ CUDA
æ‚¨çš„ RTX 4060 éœ€è¦æœ€æ–°é©…å‹•å’Œ CUDA 11.8 ä»¥å•Ÿç”¨ GPU åŠ é€Ÿã€‚

1. **æª¢æŸ¥ç›®å‰é©…å‹•ç‰ˆæœ¬**ï¼š
   - é–‹å•Ÿå‘½ä»¤æç¤ºå­—å…ƒï¼ˆCMDï¼‰æˆ–çµ‚ç«¯æ©Ÿï¼Œè¼¸å…¥ï¼š
     ```
     nvidia-smi
     ```
   - å¦‚æœé¡¯ç¤ºé©…å‹•ç‰ˆæœ¬ï¼ˆæ‡‰ â‰¥ 535ï¼‰ï¼Œç¹¼çºŒï¼›å¦å‰‡ä¸‹è¼‰æœ€æ–°é©…å‹•ã€‚

2. **å®‰è£/æ›´æ–° NVIDIA é©…å‹•**ï¼š
   - å‰å¾€ NVIDIA å®˜ç¶²ï¼ˆhttps://www.nvidia.com/Download/index.aspxï¼‰ï¼Œé¸æ“‡ GeForce > RTX 40 Series (Notebooks) > RTX 4060 Laptop GPU > Windows 11/10 > Game Ready Driverã€‚
   - ä¸‹è¼‰ä¸¦å®‰è£æœ€æ–°ç‰ˆæœ¬ï¼ˆ2025 å¹´ 11 æœˆæ¨è–¦ 560+ ç³»åˆ—ï¼‰ã€‚å®‰è£å¾Œé‡å•Ÿé›»è…¦ã€‚

3. **å®‰è£ CUDA 11.8**ï¼š
   - ä¸‹è¼‰ CUDA Toolkit 11.8 å¾ NVIDIA é–‹ç™¼è€…ç¶²ç«™ï¼ˆhttps://developer.nvidia.com/cuda-11-8-0-download-archiveï¼‰ã€‚
   - é¸æ“‡ Windows > x86_64 > exe (local) > ä¸‹è¼‰ä¸¦åŸ·è¡Œå®‰è£ç¨‹å¼ã€‚é¸æ“‡ã€Œè‡ªè¨‚å®‰è£ã€ï¼Œç¢ºä¿å‹¾é¸ cuDNN å’Œæ¨£æœ¬ã€‚
   - å®‰è£å¾Œï¼Œé‡å•Ÿé›»è…¦ä¸¦é©—è­‰ï¼š
     ```
     nvcc --version
     ```
     æ‡‰é¡¯ç¤º 11.8ã€‚

4. **é©—è­‰ GPU**ï¼š
   - é‹è¡Œ `nvidia-smi`ï¼Œç¢ºèª CUDA ç‰ˆæœ¬ç‚º 11.8ï¼Œä¸” GPU å¯ç”¨ã€‚

#### æ­¥é©Ÿ 2: å®‰è£ Anaconda/Minicondaï¼ˆå¦‚æœæœªå®‰è£ï¼‰
DeepSeek-OCR æ¨è–¦ä½¿ç”¨ Conda ç®¡ç†ç’°å¢ƒã€‚

1. ä¸‹è¼‰ Minicondaï¼ˆè¼•é‡ç‰ˆï¼‰å¾ https://docs.conda.io/en/latest/miniconda.htmlï¼ˆé¸æ“‡ Windows 64-bitï¼‰ã€‚
2. å®‰è£ä¸¦é‡å•Ÿçµ‚ç«¯æ©Ÿã€‚
3. é©—è­‰ï¼š
   ```
   conda --version
   ```

#### æ­¥é©Ÿ 3: å»ºç«‹ä¸¦å•Ÿç”¨ Conda ç’°å¢ƒ
å»ºç«‹å°ˆç”¨ç’°å¢ƒä»¥åŒ¹é…å®˜æ–¹æ¸¬è©¦ç‰ˆæœ¬ï¼ˆPython 3.12.9ã€PyTorch 2.6.0ã€CUDA 11.8ï¼‰ã€‚

1. é–‹å•Ÿçµ‚ç«¯æ©Ÿï¼Œè¼¸å…¥ï¼š
   ```
   conda create -n deepseek-ocr python=3.12.9 -y
   conda activate deepseek-ocr
   ```

2. **å®‰è£ PyTorch with CUDA 11.8**ï¼š
   ```
   conda install pytorch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y
   ```

3. **å®‰è£å…¶ä»–ä¾è³´**ï¼š
   ```
   pip install transformers==4.46.3 tokenizers==0.20.3
   pip install flash-attn==2.7.3 --no-build-isolation
   pip install pillow accelerate safetensors
   ```
   - `flash-attn` æ˜¯ç”¨æ–¼åŠ é€Ÿæ³¨æ„åŠ›çš„é—œéµå¥—ä»¶ï¼›å¦‚æœç·¨è­¯å¤±æ•—ï¼Œå¯å˜—è©¦ `pip install flash-attn --no-build-isolation` æˆ–æª¢æŸ¥ CUDA è·¯å¾‘ã€‚

4. **é©—è­‰å®‰è£**ï¼š
   ```
   python -c "import torch; print(torch.cuda.is_available())"
   ```
   æ‡‰è¼¸å‡º `True`ã€‚

#### æ­¥é©Ÿ 4: å…‹éš† GitHub å€‰åº«ä¸¦ä¸‹è¼‰æ¨¡å‹
1. å®‰è£ Gitï¼ˆå¦‚æœæœªå®‰è£ï¼Œå¾ https://git-scm.com/downloadsï¼‰ã€‚
2. å…‹éš†å®˜æ–¹å€‰åº«ï¼š
   ```
   git clone https://github.com/deepseek-ai/DeepSeek-OCR.git
   cd DeepSeek-OCR
   ```

3. **ä¸‹è¼‰æ¨¡å‹**ï¼ˆå¾ Hugging Faceï¼‰ï¼š
   - å¦‚æœæ‚¨æœ‰ Hugging Face å¸³è™Ÿï¼ˆæ¨è–¦ï¼ŒåŠ é€Ÿä¸‹è¼‰ï¼‰ï¼Œç™»å…¥ï¼š
     ```
     huggingface-cli login
     ```
     ï¼ˆè¼¸å…¥æ‚¨çš„ tokenï¼Œå¾ https://huggingface.co/settings/tokens å–å¾—ï¼‰ã€‚
   - ä¸‹è¼‰æ¨¡å‹ï¼š
     ```
     huggingface-cli download deepseek-ai/DeepSeek-OCR --local-dir ./models
     ```
   - é€™æœƒä¸‹è¼‰ç´„ 14GB çš„æ¨¡å‹æª”æ¡ˆåˆ° `./models` è³‡æ–™å¤¾ã€‚å¦‚æœç„¡å¸³è™Ÿï¼Œå¯ç›´æ¥ç”¨ Python è…³æœ¬ä¸‹è¼‰ï¼ˆè¦‹æ­¥é©Ÿ 5ï¼‰ã€‚

#### æ­¥é©Ÿ 5: é‹è¡Œæ¨ç†è…³æœ¬
å®˜æ–¹æä¾›ç°¡å–®çš„ Transformers æ¨ç†ç¯„ä¾‹ã€‚å»ºç«‹ä¸€å€‹æ¸¬è©¦è…³æœ¬ `test_ocr.py`ï¼š

```python
from transformers import AutoModel, AutoTokenizer
import torch
from PIL import Image

# è¨­å®šæ¨¡å‹åç¨±å’Œè·¯å¾‘
model_name = './models'  # æˆ– 'deepseek-ai/DeepSeek-OCR' å¦‚æœæœªæœ¬åœ°ä¸‹è¼‰
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name,
    _attn_implementation='flash_attention_2',
    trust_remote_code=True,
    use_safetensors=True
)
model = model.eval().cuda().to(torch.bfloat16)  # ä½¿ç”¨ bfloat16 ç¯€çœè¨˜æ†¶é«”

# è¼‰å…¥åœ–åƒï¼ˆæ›¿æ›ç‚ºæ‚¨çš„åœ–åƒè·¯å¾‘ï¼‰
image = Image.open("path/to/your/image.png").convert("RGB")  # æ”¯æ´ PNG/JPG ç­‰

# æç¤ºè©ï¼ˆå®˜æ–¹æ¨è–¦ç°¡å–®æç¤ºï¼‰
prompt = "<image>\nFree OCR."

# ç·¨ç¢¼è¼¸å…¥
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
inputs["image"] = image

# ç”Ÿæˆè¼¸å‡º
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=512, do_sample=False)

# è§£ç¢¼çµæœ
result = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(result)
```

1. å°‡è…³æœ¬å„²å­˜åˆ° `DeepSeek-OCR` è³‡æ–™å¤¾ã€‚
2. æº–å‚™ä¸€å¼µæ¸¬è©¦åœ–åƒï¼ˆä¾‹å¦‚ `test.png`ï¼‰ï¼Œæ”¾åœ¨åŒä¸€è³‡æ–™å¤¾ã€‚
3. é‹è¡Œï¼š
   ```
   python test_ocr.py
   ```
   - è¼¸å‡ºæ‡‰ç‚ºåœ–åƒä¸­çš„æå–æ–‡æœ¬ï¼ˆä¾‹å¦‚ Markdown æ ¼å¼ï¼‰ã€‚

#### æ­¥é©Ÿ 6: é€²éšä½¿ç”¨èˆ‡å„ªåŒ–
- **æ‰¹æ¬¡è™•ç†**ï¼šä½¿ç”¨ vLLM åŠ é€Ÿï¼ˆå®˜æ–¹æ”¯æ´ï¼‰ã€‚å®‰è£ï¼š
  ```
  pip install vllm==0.8.5
  ```
  ç¯„ä¾‹è…³æœ¬ï¼ˆ`batch_ocr.py`ï¼‰ï¼š
  ```python
  from vllm import LLM, SamplingParams
  from vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor
  from PIL import Image

  llm = LLM(
      model="./models",
      enable_prefix_caching=False,
      mm_processor_cache_gb=0,
      logits_processors=[NGramPerReqLogitsProcessor]
  )

  image = Image.open("path/to/your/image.png").convert("RGB")
  prompt = "<image>\nFree OCR."
  sampling_params = SamplingParams(temperature=0.0, max_tokens=512)

  outputs = llm.generate(
      [{"prompt": prompt, "multi_modal_data": {"image": image}}],
      sampling_params
  )
  print(outputs[0].outputs[0].text)
  ```
  é‹è¡Œï¼š`python batch_ocr.py`ã€‚

- **PDF æ”¯æ´**ï¼šæ¨¡å‹ä¸ç›´æ¥æ”¯æ´ PDFï¼Œå…ˆè½‰æ›ç‚ºåœ–åƒï¼ˆä½¿ç”¨ `pdf2image` å¥—ä»¶ï¼š`pip install pdf2image`ï¼‰ï¼Œç„¶å¾Œé€é  OCRã€‚
- **è¨˜æ†¶é«”å„ªåŒ–**ï¼šæ‚¨çš„ 64GB RAM å’Œ 8GB VRAM è¶³å¤ ï¼›è‹¥ OOM éŒ¯èª¤ï¼Œä½¿ç”¨ `torch.bfloat16` æˆ–æ¸›å° `max_new_tokens`ã€‚
- **Docker éƒ¨ç½²ï¼ˆé¸ç”¨ï¼‰**ï¼šå¦‚æœæƒ³å®¹å™¨åŒ–ï¼Œå¾å€‰åº«å»ºç«‹ Dockerfileï¼Œæˆ–ä½¿ç”¨å®˜æ–¹ç¯„ä¾‹å»ºç½®æ˜ åƒã€‚

#### ç–‘é›£æ’è§£
- **CUDA éŒ¯èª¤**ï¼šç¢ºèª `torch.cuda.is_available()` ç‚º Trueï¼›è‹¥å¦ï¼Œé‡è£ PyTorchã€‚
- **Flash Attention ç·¨è­¯å¤±æ•—**ï¼šç¢ºä¿ CUDA 11.8 ç’°å¢ƒè®Šæ•¸æ­£ç¢ºï¼ˆ`echo $PATH` åŒ…å« `/usr/local/cuda-11.8/bin`ï¼‰ã€‚
- **ä¸‹è¼‰ç·©æ…¢**ï¼šä½¿ç”¨é¡åƒï¼ˆå¦‚ ModelScopeï¼‰æˆ– VPNã€‚
- **æ•ˆèƒ½**ï¼šRTX 4060 é æœŸæ¯å¼µåœ–åƒè™•ç† 10-30 ç§’ï¼›è‹¥æ…¢ï¼Œæª¢æŸ¥ GPU ä½¿ç”¨ç‡ï¼ˆ`nvidia-smi`ï¼‰ã€‚

å¦‚æœæ­¥é©Ÿä¸­é‡åˆ°éŒ¯èª¤ï¼Œè«‹æä¾›éŒ¯èª¤è¨Šæ¯ï¼Œæˆ‘å¯ä»¥é€²ä¸€æ­¥å”åŠ©ã€‚éƒ¨ç½²æˆåŠŸå¾Œï¼Œæ‚¨å³å¯æœ¬åœ°é‹è¡Œ OCR ä»»å‹™ï¼
æˆ‘ä¾†å¹«ä½ æä¾› DeepSeek OCR æœ¬åœ°éƒ¨ç½²çš„è©³ç´°æ­¥é©Ÿã€‚ä½ çš„é…ç½®å¾ˆä¸éŒ¯ï¼ˆRTX 4060 + 64GB RAMï¼‰ï¼Œå®Œå…¨å¯ä»¥é †æš¢é‹è¡Œã€‚è®“æˆ‘å…ˆæœç´¢æœ€æ–°çš„éƒ¨ç½²è³‡è¨Šã€‚æ ¹æ“šæœç´¢çµæœï¼Œæˆ‘ç‚ºä½ æ•´ç†äº†è©³ç´°çš„ DeepSeek OCR æœ¬åœ°éƒ¨ç½²æ­¥é©Ÿã€‚ä½ çš„ RTX 4060 + 64GB RAM é…ç½®éå¸¸é©åˆé‹è¡Œé€™å€‹æ¨¡å‹ï¼ŒDeepSeek-OCR åªæœ‰ 3B åƒæ•¸ï¼Œæ¬Šé‡æ–‡ä»¶åƒ… 6.67GBï¼ŒRTX 3060 ç­‰å…¥é–€ç´šé¡¯å¡å³å¯æµæš¢é‹è¡Œã€‚

## **å®Œæ•´éƒ¨ç½²æ­¥é©Ÿ**

### **æ­¥é©Ÿ 1ï¼šå®‰è£å‰ç½®è»Ÿä»¶**

1. **å®‰è£ Anaconda æˆ– Miniconda**ï¼ˆå¦‚æœé‚„æ²’å®‰è£ï¼‰
   - ä¸‹è¼‰ï¼šhttps://www.anaconda.com/download
   - å®‰è£å®Œæˆå¾Œé‡å•Ÿçµ‚ç«¯

2. **ç¢ºèª NVIDIA é©…å‹•å·²å®‰è£**
   - æ‰“é–‹å‘½ä»¤æç¤ºå­—å…ƒï¼ˆCMDï¼‰è¼¸å…¥ï¼š
   ```bash
   nvidia-smi
   ```
   - æ‡‰è©²èƒ½çœ‹åˆ°ä½ çš„ RTX 4060 é¡¯å¡è³‡è¨Š

### **æ­¥é©Ÿ 2ï¼šå‰µå»ºè™›æ“¬ç’°å¢ƒ**

æ‰“é–‹ Anaconda Prompt æˆ– CMDï¼ŒåŸ·è¡Œï¼š

```bash
# å‰µå»º Python 3.12.9 ç’°å¢ƒ
conda create -n deepseek-ocr python=3.12.9 -y

# å•Ÿå‹•ç’°å¢ƒ
conda activate deepseek-ocr
```

### **æ­¥é©Ÿ 3ï¼šå®‰è£æ ¸å¿ƒå¥—ä»¶**

æŒ‰ç…§å®˜æ–¹æ¸¬è©¦çš„ç’°å¢ƒé…ç½® cuda11.8+torch2.6.0ï¼š

```bash
# å®‰è£ PyTorchï¼ˆCUDA 11.8 ç‰ˆæœ¬ï¼‰
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118

# å®‰è£å…¶ä»–ä¾è³´
pip install transformers==4.46.3 tokenizers==0.20.3 einops addict easydict

# å®‰è£ Flash Attentionï¼ˆåŠ é€Ÿæ¨ç†ï¼‰
pip install flash-attn==2.7.3 --no-build-isolation
```

**æ³¨æ„**ï¼šFlash Attention å®‰è£å¯èƒ½éœ€è¦ 5-10 åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚

### **æ­¥é©Ÿ 4ï¼šä¸‹è¼‰é …ç›®ä»£ç¢¼**

```bash
# å…‹éš†å®˜æ–¹å€‰åº«
git clone https://github.com/deepseek-ai/DeepSeek-OCR.git

# é€²å…¥ç›®éŒ„
cd DeepSeek-OCR
```

å¦‚æœæ²’æœ‰ gitï¼Œå¯ä»¥ç›´æ¥åˆ° GitHub ä¸‹è¼‰ ZIP æª”æ¡ˆä¸¦è§£å£“ã€‚

### **æ­¥é©Ÿ 5ï¼šæ¸¬è©¦é‹è¡Œ**

å‰µå»ºä¸€å€‹æ¸¬è©¦è…³æœ¬ `test_ocr.py`ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image
import torch

# åŠ è¼‰æ¨¡å‹å’Œåˆ†è©å™¨
model_name = "deepseek-ai/DeepSeek-OCR"
print("æ­£åœ¨åŠ è¼‰æ¨¡å‹...")
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    trust_remote_code=True,
    torch_dtype=torch.float16
).to("cuda")

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# åŠ è¼‰åœ–ç‰‡
image_path = "your_image.jpg"  # æ›¿æ›æˆä½ çš„åœ–ç‰‡è·¯å¾‘
image = Image.open(image_path)

# é€²è¡Œ OCR è­˜åˆ¥
prompt = "<image>\n<|grounding|>Convert the document to markdown."
inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

# ç”Ÿæˆçµæœ
print("æ­£åœ¨è­˜åˆ¥...")
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=2048)
    
result = tokenizer.decode(outputs[0], skip_special_tokens=True)
print("\nè­˜åˆ¥çµæœï¼š")
print(result)
```

é‹è¡Œæ¸¬è©¦ï¼š
```bash
python test_ocr.py
```

### **æ­¥é©Ÿ 6ï¼šä½¿ç”¨ Gradio å»ºç«‹ Web ä»‹é¢ï¼ˆå¯é¸ï¼‰**

å®‰è£ Gradioï¼š
```bash
pip install gradio
```

å‰µå»º `web_ui.py`ï¼š

```python
import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image
import torch

# è¼‰å…¥æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "deepseek-ai/DeepSeek-OCR",
    trust_remote_code=True,
    torch_dtype=torch.float16
).to("cuda")

tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/DeepSeek-OCR", trust_remote_code=True)

def ocr_image(image):
    prompt = "<image>\n<|grounding|>Convert the document to markdown."
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=2048)
    
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# å»ºç«‹ä»‹é¢
interface = gr.Interface(
    fn=ocr_image,
    inputs=gr.Image(type="pil"),
    outputs=gr.Textbox(label="è­˜åˆ¥çµæœ"),
    title="DeepSeek OCR æœ¬åœ°éƒ¨ç½²",
    description="ä¸Šå‚³åœ–ç‰‡é€²è¡Œæ–‡å­—è­˜åˆ¥"
)

interface.launch(server_name="0.0.0.0", server_port=7860)
```

é‹è¡Œ Web ä»‹é¢ï¼š
```bash
python web_ui.py
```

ç„¶å¾Œåœ¨ç€è¦½å™¨æ‰“é–‹ `http://localhost:7860`

## **æ•ˆèƒ½é ä¼°**

DeepSeek-OCR æ”¯æŒå››ç¨®åˆ†è¾¨ç‡æ¨¡å¼ï¼ˆå¾ 512Ã—512 åˆ° 1280Ã—1280ï¼‰ï¼Œå¯ä»¥è™•ç†è¤‡é›œæ’ç‰ˆæ–‡æª”ã€‚åœ¨ä½ çš„ RTX 4060 ä¸Šï¼š
- å–®å¼µåœ–ç‰‡è­˜åˆ¥ï¼šç´„ 2-5 ç§’
- æ¯å°æ™‚å¯è™•ç†ï¼šç´„ 1000-2000 é 
- é¡¯å­˜ä½”ç”¨ï¼šç´„ 7-8GB

## **å¸¸è¦‹å•é¡Œæ’æŸ¥**

1. **CUDA éŒ¯èª¤**ï¼šç¢ºèª `nvidia-smi` å¯ä»¥é‹è¡Œ
2. **è¨˜æ†¶é«”ä¸è¶³**ï¼šé™ä½æ‰¹æ¬¡å¤§å°æˆ–åœ–ç‰‡è§£æåº¦
3. **æ¨¡å‹ä¸‹è¼‰æ…¢**ï¼šå¯ä»¥ä½¿ç”¨é¡åƒç«™æˆ–æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆ

éœ€è¦æˆ‘æä¾›æ›´è©³ç´°çš„æŸå€‹æ­¥é©Ÿèªªæ˜å—ï¼Ÿ